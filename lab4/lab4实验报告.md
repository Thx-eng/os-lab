## 练习1：分配并初始化一个进程控制块

### 1. 代码实现

在 kern/process/proc.c 文件的 alloc_proc 函数中，我们需要对新分配的 proc_struct 结构体成员进行初始化。以下是新增的初始化代码逻辑：

```cpp
// 在 alloc_proc 函数内部，proc != NULL 的判断之后：

proc->state = PROC_UNINIT;                   // 设置进程状态为未初始化
proc->pid = -1;                              // 未分配PID，初始化为-1
proc->runs = 0;                              // 运行时间为0
proc->kstack = 0;                            // 内核栈地址暂时为0，后续由 do_fork 分配
proc->need_resched = 0;                      // 不需要调度
proc->parent = NULL;                         // 父进程为空
proc->mm = NULL;                             // 内存管理结构为空
memset(&(proc->context), 0, sizeof(struct context)); // 清空上下文变量，确保无残留垃圾数据
proc->tf = NULL;                             // 中断帧指针为空，后续在 copy_thread 中设置
proc->pgdir = boot_pgdir_pa;                 // 页目录表基址设置为内核页目录表基址（关键）
proc->flags = 0;                             // 标志位为0
memset(proc->name, 0, PROC_NAME_LEN + 1);    // 进程名清空
```

### 2. 设计实现过程简述

alloc_proc 函数的作用是创建一个新的进程控制块（PCB），它是操作系统管理进程的核心数据结构。初始化的主要设计思路是确保进程在刚创建时处于一个**干净且安全**的状态（PROC_UNINIT），避免因未初始化的内存（野指针或垃圾数据）导致内核崩溃。

具体初始化逻辑如下：

1. **状态与标识**：将 state 设为 PROC_UNINIT，pid 设为 -1。这表示虽然内存已分配，但进程尚未构建完成，也不具备参与调度的资格。
2. **资源占位**：kstack（内核栈）、mm（虚拟内存管理）、parent（父进程）、tf（中断帧）等成员变量均初始化为 0 或 NULL。这些资源并非在 PCB 分配时立即产生，而是在后续的 do_fork 阶段根据父进程或内核线程的具体情况进行创建和拷贝。
3. **页表设置**：将 pgdir 指向 boot_pgdir_pa（内核启动页表物理地址）。这是一个关键点，因为即使是内核线程，也需要一个有效的页表来进行地址映射。在进程建立自己的页表之前，它默认共享内核的页表。
4. **上下文清理**：使用 memset 将 context 区域清零。context 用于内核上下文切换，如果这里留有随机数据，可能会导致第一次调度该进程时跳转到错误的地址。

### 3. 问题回答

### 请说明 proc_struct 中 struct context context 和 struct trapframe *tf 成员变量含义和在本实验中的作用是啥？

#### 1. struct context context

- **含义**：
  context 结构体保存了进程在**内核态**进行切换时，CPU 的寄存器状态（在 RISC-V 中通常包括 ra, sp, s0-s11 等被调用者保存寄存器）。
- **作用**：
  它是**进程上下文切换**（Context Switch）的基础。当调度器调用 switch_to 函数切换进程时，会保存当前进程的寄存器到其 context 中，并从下一个进程的 context 中恢复寄存器。这使得进程能够在内核中“暂停”和“继续”执行。对于新创建的进程，我们会在 copy_thread 中设置 context.ra = forkret，context.sp = kstacktop，确保新进程被调度时能从 forkret 函数开始运行。

#### 2. struct trapframe *tf

- **含义**：
  tf 是一个指针，指向该进程**内核栈**顶部的一个 trapframe 结构。该结构记录了进程从用户态进入内核态（或在内核态发生中断）那一瞬间的 CPU 完整现场（包括所有通用寄存器、epc、status 等）。
- **作用**：
  它是**中断处理和特权级切换**的基础。
  1. 当进程执行系统调用或被时钟中断打断时，硬件和 OS 协作将现场保存在 tf 指向的位置。
  2. 在本实验的进程创建中，tf 扮演了**入口参数构造**的角色。内核会伪造一个 tf，当新进程通过 forkret 开始运行时，forkret 会最终调用 __trapret（汇编），利用这个伪造的 tf 将 CPU 寄存器恢复，从而“返回”到我们设定的入口点（例如 init_main 或用户程序的起点），完成新进程的启动。

## 练习2：为新创建的内核线程分配资源

### 一、do_fork 的设计实现过程

1. **分配进程控制块 (PCB)**

```cpp
proc = alloc_proc();
if (proc == NULL)
    goto fork_out;
```
- 目的：为新进程分配一个进程控制块。这个结构是内核管理进程所需的所有信息的载体。
- 实现：`alloc_proc()` 函数从内核的空闲进程链表（proc_list）中找到一个未使用的 `proc_struct` 结构。
- 错误处理：如果内存不足或没有空闲的 PCB，`alloc_proc()` 会返回 NULL。此时 `do_fork` 会跳转到 `fork_out` 标签，结束创建过程并返回错误。


2. **分配内核栈**
```cpp
if (setup_kstack(proc) != 0)
    goto bad_fork_cleanup_proc;
```
调用 `setup_kstack(proc)` 分配 `KSTACKPAGE` 大小的页，并把 `proc->kstack` 设置为该页的内核虚拟地址。必须在 `copy_thread()` 之前完成，因为 `copy_thread()` 会把 trapframe/上下文写到内核栈上。

3. **填写运行时字段**

- `proc->pid = get_pid()`：为新进程分配 pid。
- `proc->parent = current`：记录父进程。
- `proc->runs = 0; proc->need_resched = 0; proc->mm = NULL; proc->flags = 0; proc->state = PROC_UNINIT;` 等字段初始化。

4. **复制/共享内存管理信息**
```cpp
if (copy_mm(clone_flags, proc) != 0)
    goto bad_fork_cleanup_kstack;
```
这是 fork 操作的核心之一。它需要将父进程的地址空间（代码、数据、堆、共享库等）复制给子进程。

`copy_mm` 函数的行为由 `clone_flags `参数控制，按 `clone_flags `决定共享或复制 mm

5. **复制原进程上下文到新进程**
```cpp
copy_thread(proc, stack, tf);
```
- 目的：确保子进程在被调度执行时，能够从父进程 fork 时的状态继续运行。这包括设置子进程的指令指针（eip）、栈指针（esp）以及通用寄存器的值。
- 实现：`copy_thread` 函数是关键。

    - 它会访问父进程的中断帧 tf（trapframe_t），这个帧记录了父进程执行 int 0x80（系统调用）前的所有寄存器状态。
    - 它会在子进程的内核栈上，精心构造一个看起来像是子进程刚刚执行完 int 0x80 系统调用的上下文。
    - 最重要的一步是修改返回地址。父进程调用 fork() 后，会从系统调用返回到用户态的下一条指令。子进程也需要从同样的位置开始执行。但如何让一个返回值区分父子进程呢？copy_thread 会将子进程内核栈上的返回地址（tf->eip）设置为一个内核函数（通常是 forkret），并在栈上压入一个值（通常是 0）。这样，当子进程第一次被调度时，它会从 forkret 开始执行，这个函数会通过 iret 指令恢复上下文，最终让子进程在用户态的 fork() 调用处返回 0。而父进程则会从 sys_fork 函数中返回，得到子进程的 PID。
    参数 stack 通常是 NULL 或用于指定用户栈，在 do_fork 中主要使用 tf 来获取父进程上下文。


6. **将新进程添加到进程列表**
```cpp
hash_proc(proc);
list_add(&proc_list, &proc->list_link);
```
- 目的：将新创建的进程纳入内核的统一管理。
- 实现：

    `hash_proc(proc)`：将进程的 pid 进行哈希运算，然后将 proc 结构添加到对应的哈希桶链表中。这样做可以加速 `find_pid` 等通过 PID 查找进程的操作。
    `list_add(&proc_list, &proc->list_link)`：将 proc 结构添加到全局的 proc_list 链表中。这个链表包含了系统中所有的进程，方便进行遍历（例如在调度或 ps 命令中）。


7. **唤醒新进程**
```cpp
wakeup_proc(proc)
```
- 目的：让新创建的进程从初始的 `PROC_UNINIT` 或 `PROC_SLEEPING` 状态变为 `PROC_RUNNABLE` 状态，使其有资格被调度器选中并执行。
- 实现：`wakeup_proc` 函数会将进程的状态 `proc->state` 修改为 `PROC_RUNNABLE`，并将其加入到就绪队列（run_queue）中。

8. **返回新进程号**
```cpp
nr_process++;
ret = proc->pid;
```
- 目的：更新系统的进程计数，并将子进程的 PID 作为 `do_fork` 函数的返回值，最终传递给父进程的 fork() 调用。
- 实现：`nr_process` 是一个全局计数器，记录了当前系统中活跃的进程总数。`ret = proc->pid` 将新进程的 PID 存入返回值变量。


### 二、ucore 是否给每个新 fork 的线程一个唯一的 id？

是。

`get_pid()` 函数通过严谨的 “自增尝试 + 冲突检测 + 边界保障” 逻辑，确保了每次分配的 PID 在当前系统中是唯一的。

1. 初始化与自增：基于 “上次分配的 PID” 继续推进
```cpp
static int next_safe = MAX_PID, last_pid = MAX_PID;
if (++last_pid >= MAX_PID)
{
    last_pid = 1;  // 超过最大值则从 1 开始（循环复用）
    goto inside;
}
```
- `last_pid` 是 静态变量：第一次调用时初始为 `MAX_PID`，自增后变成 `MAX_PID+1`，触发 `>= MAX_PID`，重置为 1；后续调用会从 “上次分配的 PID +1” 开始，避免每次都从 1 遍历，提高效率。
- 这里的 “循环复用” 是合理的：当旧进程退出后，其 PID 会被释放，后续新进程可以复用这个 PID。

2. 冲突检测：遍历所有进程，确保 PID 未被占用
```cpp
inside:
next_safe = MAX_PID;  // 重置“安全上限”，准备重新检测
repeat:
le = list;
while ((le = list_next(le)) != list)  // 遍历全局进程链表 proc_list
{
    proc = le2proc(le, list_link);  // 从链表节点获取进程控制块
    if (proc->pid == last_pid)  // 发现 PID 冲突（已被现有进程占用）
    {
        // 冲突处理：自增 last_pid，重新检查边界
        if (++last_pid >= next_safe)
        {
            if (last_pid >= MAX_PID) last_pid = 1;  // 超过上限则重置为 1
            next_safe = MAX_PID;  // 重置安全上限，重新遍历
            goto repeat;  // 回到开头，重新遍历所有进程检测新 PID
        }
    }
    // 优化逻辑：记录“比当前 last_pid 大的最小已占用 PID”，减少后续遍历范围
    else if (proc->pid > last_pid && next_safe > proc->pid)
    {
        next_safe = proc->pid;
    }
}
```

这是保证 PID 唯一的 核心步骤：
- 遍历 `proc_list`（全局所有进程的链表），逐个检查 `last_pid` 是否已被某个进程使用；
- 若发现冲突（`proc->pid == last_pid`），立即自增 `last_pid`，并重新触发遍历检测（`goto repeat`），直到找到 “未被任何进程占用” 的 PID；
- `next_safe` 的作用是优化：比如当前 `last_pid`=3，发现 pid=5 已被占用，就把 `next_safe=5`，后续自增到 4 时，只要 4 < `next_safe`，就不用再遍历（因为 4 肯定没被占用），减少不必要的循环。

3. 边界保障：断言确保 “PID 总数> 最大进程数”
```cpp
static_assert(MAX_PID > MAX_PROCESS);
```
    这个断言确保 “系统可用的 PID 数量> 最大进程数”，意味着 永远不可能出现 “所有 PID 都被占用” 的情况，从而避免了 “找不到空闲 PID” 的死循环。

因此，ucore能做到给每个新fork的线程一个唯一的id。

## 练习3：实现 proc_run 并说明行为

### 1. 代码（proc_run 实现）

proc_run 的实现放在 kern/process/proc.c 中：

```c
void proc_run(struct proc_struct *proc)
{
    if (proc == current)
    {
        return;
    }

    bool intr_flag;
    local_intr_save(intr_flag);

    struct proc_struct *prev = current;

    /* 切换当前进程指针 */
    current = proc;
    /* 统计运行次数 */
    proc->runs++;

    /* 切换页表 */
    lsatp(proc->pgdir);

    /* 上下文切换 */
    switch_to(&prev->context, &proc->context);

    local_intr_restore(intr_flag);
}

```

### 2. 说明

- 若目标进程就是 current，则直接返回，不做切换。
- 使用 local_intr_save 保存并禁止本地中断，切换完成后通过 local_intr_restore 恢复原始中断状态，防止在切换过程中被中断打断导致上下文不一致。
- 将 current 更新为目标进程，并统计 runs。
- 调用 lsatp 切换 SATP（页表基址），使 MMU 使用新进程的地址空间。
- 调用 switch_to(from, to) 完成寄存器上下文切换（由 kern/process/switch.S 提供）。
- 恢复中断标志。

---

## 练习题：在本实验执行过程中创建且运行了几个内核线程？

调用 proc_init 时创建并运行了两个内核线程：
- idleproc（第 0 个内核线程）：系统占位线程，在无其他 runnable 线程时运行空循环。
- initproc（第 1 个内核线程）：通过 kernel_thread 创建，第一个实际执行任务的内核线程（本实验用于输出 "Hello World" 验证线程创建与调度）。

因此本实验创建并运行了 2 个内核线程。

---

## 扩展练习 Challenge

### 问：说明语句 local_intr_save(intr_flag); ... local_intr_restore(intr_flag); 是如何实现开关中断的？

- 实现原理
  - local_intr_save 调用内联函数 __intr_save()：读取 CSR sstatus 的 SIE 位（SSTATUS_SIE）。若 SIE==1（中断已使能），则调用 intr_disable() 写 sstatus 关闭 SIE 并返回 1；否则直接返回 0。也就是把“调用时的中断使能状态”保存到 intr_flag。
  - local_intr_restore 调用 __intr_restore(flag)：仅当传入 flag 为真时调用 intr_enable() 恢复 SIE，从而恢复中断。
- 作用与好处
  - 能正确保存并恢复原始中断使能状态，支持嵌套禁中断临界区，避免无条件使能中断导致中断嵌套错误。
  - intr_disable/ intr_enable 通过写 CSR(sstatus) 实际执行关/开中断操作，保证与硬件状态一致。

(sync.h 中实现如下)
```c
static inline bool __intr_save(void) {
    if (read_csr(sstatus) & SSTATUS_SIE) {
        intr_disable();
        return 1;
    }
    return 0;
}

static inline void __intr_restore(bool flag) {
    if (flag) {
        intr_enable();
    }
}

#define local_intr_save(x) \
    do { x = __intr_save(); } while (0)
#define local_intr_restore(x) __intr_restore(x);
```

---

## 思考题：get_pte() 中两段相似代码及合并查找/分配的利弊

### Q1：为什么两段代码相像？

- 多级页表在每一中间层的处理步骤相同：检查当前层表项是否有效（PTE_V），若无且允许创建则分配一页作为下一层页表、清零并写入下一级页表的物理页号（ppn）。
- sv32/sv39/sv48 的差异仅在层数与每层索引位宽，不改变“检查/分配/写入下一级页表页”的基本逻辑。因此代码在不同层的实现看起来高度相似。

### Q2：把查找和分配合并到一个函数（get_pte(pgdir, la, create)）好吗？是否有必要拆开？

- 优点
  - 使用方便：调用者只需一次调用即可获得可用的 pte，常用于需要按需创建页表的场景（如 page_insert、boot_map_segment）。
  - 简化调用者逻辑，减少重复代码。
- 缺点
  - 职责混合：函数同时负责查找与分配，语义不够单一，不利于阅读与单元测试。
  - 灵活性受限：某些场景只需查找而不允许分配，或需要对分配失败做定制处理，单一函数不够清晰。
  - 若要支持多种分页模式，展开多层代码可读性差且易出错。
- 想法
  - 对教学/小型内核，也就是本实验，带 create 参数的单函数实现实用且足够。
  - 对更复杂或追求可维护性的内核，可以将“纯查找（lookup）”与“按需创建（ensure/alloc）”拆分为两个明确接口，或设计通用层循环实现并提供封装函数以兼顾可用性与可维护性。

---

## 本实验中重要的知识点，以及与对应的OS原理中的知识点

### 实验知识点与操作系统原理对应说明

#### 1. 内核线程

**对应的操作系统原理：线程 / 轻量级进程**

**含义：**
 操作系统原理中，线程是 CPU 调度的最小单位，而进程是资源分配单位。内核线程完全由内核管理，仅运行在内核态。

**关系：**
 本实验中所有内核线程共享同一份内核地址空间（boot_pgdir），可以理解为“所有线程属于同一个内核进程”。这符合理论中“同一进程的线程共享地址空间”的概念。

**差异：**
 普通用户进程有独立的虚拟地址空间；实验中的内核线程没有独立的用户空间内存（mm 指针为空或共享），并且始终处于高特权级。

------

#### 2. 进程控制块

**对应的操作系统原理：进程控制块 / 线程控制块**

**含义：**
 这是操作系统用来感知进程或线程存在的基本数据结构，包含 PID、状态、寄存器上下文、栈指针等信息。

**关系：**
 uCore 使用同一个结构 proc_struct 来同时表示进程和线程，而理论中通常由 PCB 表示进程，TCB 表示线程，两者分离。

**差异：**
 实验中的 proc_struct 较为简化，主要关注上下文切换和内核栈等基础功能，还没有加入文件系统、信号处理等更完整的进程管理字段。

------

#### 3. 上下文切换

**对应的操作系统原理：上下文切换**

**含义：**
 上下文切换指暂停当前执行的任务，保存其寄存器现场，并恢复另一个任务的寄存器，让 CPU 执行新的线程。

**关系：**
 实验中的 context 结构体保存了需要切换的寄存器；switch_to 汇编函数实现了上下文切换中最核心的步骤：“保存旧栈顶，加载新栈顶”。

**差异：**
 实验仅切换内核态寄存器，没有涉及用户态 ↔ 内核态的特权级切换（这属于中断处理范畴），也没有页面表切换（因为所有内核线程共享内核页表）。

------

#### 4. 中断帧

**对应的操作系统原理：中断现场保护 / 用户-内核边界管理**

**含义：**
 中断帧用于记录 CPU 在中断或异常发生瞬间的完整状态。

**关系：**
 实验在创建新线程时，会人为构造一份 trapframe，用来模拟“从中断返回”时的寄存器状态，从而让新线程能够顺利开始执行。这个技巧在实际操作系统中也经常使用（例如 forkret 机制）。

**差异：**
 理论上 trapframe 主要用于处理中断，但实验中将其用于线程启动时的执行环境构造，属于技巧性质的利用。

------

#### 5. 虚拟内存描述

**对应的操作系统原理：逻辑地址空间 / 内存区域管理**

**含义：**
 用于描述进程所拥有的虚拟地址段，例如代码段、数据段、堆、栈等区域。

**关系：**
 实验引入 mm_struct 主要是为了给后续用户进程提供基础的数据结构，使操作系统具备管理进程地址空间的能力。

**差异：**
 实验采用“预映射”方式，即创建地址空间时就建立好页表；而现代操作系统大多采用按需分页（缺页异常时分配页面）。实验暂未实现缺页异常处理，这也是后续实验的重要内容。

------

#### 6. 调度器

**对应的操作系统原理：CPU 调度**

**含义：**
 调度器负责决定哪个线程或进程获得 CPU 执行。

**关系：**
 实验实现了最基本的调度策略，如先进先出或时间片轮转。当线程主动让出 CPU 或时间片用尽时，调度器会从就绪队列中选择下一个线程。

**差异：**
 实验中的调度器设计较为简单，没有实现多级反馈队列、优先级调度、优先级反转处理等高级调度策略。重点在于理解“能够切换执行流”这一核心机制。

## OS 原理中重要但实验未覆盖的知识点

### **一、进程管理相关**

1. 完整的进程状态模型

   OS 原理中，进程状态包含五状态模型（新建、就绪、运行、阻塞、退出）、双挂起进程模型（就绪挂起、等待挂起）等，挂起状态可用于内存紧张时将进程换出到外存，是现代 OS 的重要特性。实验中仅实现 `PROC_UNINIT、PROC_RUNNABLE、PROC_SLEEPING、PROC_ZOMBIE `四种基础状态，未涉及挂起状态及状态间的完整转换（如运行→就绪挂起、等待→等待挂起）。

2. 多样化的进程调度算法

   OS 原理中，时间片轮转（RR）、优先级调度、多级反馈队列调度等是实现高效并发的核心算法，适用于不同场景（如 RR 保证公平性、优先级调度满足实时需求）。实验仅实现简单的 FIFO 调度，未涉及时间片分配、优先级设置及调度算法优化。

3. 进程同步与互斥机制

   OS 原理中，临界区问题、信号量、互斥锁、条件变量等是解决并发冲突的关键，是多进程协作的基础。实验中内核线程共享内核地址空间，未涉及并发访问冲突，因此未实现任何同步互斥机制。

4. 死锁的检测与处理

   OS 原理中，死锁的产生条件（资源互斥、持有并等待、不可剥夺、循环等待）及预防、避免（银行家算法）、检测与解除是保障系统稳定性的重要内容。实验中无多进程竞争资源的场景，未涉及死锁相关机制。

5. 进程间通信（IPC）机制

   OS 原理中，管道、消息队列、共享内存、信号量集等 IPC 机制是多进程协作的核心。实验中内核线程共享内核地址空间，无需专门 IPC 机制，未实现任何 OS 级别的 IPC 通信方式。

6. 系统调用的完整流程

   OS 原理中，用户态进程通过特权级切换（如 RISC-V 的 ecall、x86 的 int 0x80）触发系统调用，需经过系统调用表查找、参数传递、内核态处理、返回值传递等完整流程。实验中仅涉及内核线程（全程内核态），未实现用户态到内核态的系统调用接口及完整处理逻辑。

### **二、内存管理相关**

1. 缺页异常与按需分页

   OS 原理中，按需分页是虚拟内存的核心特性（仅在进程访问虚拟地址时才分配物理内存并建立映射），需配合缺页异常处理程序实现。实验中虚拟内存采用预映射方式，无缺页异常处理，也无按需分配逻辑。

2. 页面置换算法

   OS 原理中，LRU、Clock、OPT 等页面置换算法是解决内存不足时 “页面换入换出” 的关键，可避免抖动。实验中无页面换入换出机制，因此未涉及任何页面置换算法。

3. 抖动（Thrashing）与负载控制

   OS 原理中，抖动是多进程并发时内存不足导致的频繁缺页现象，需通过调节并发进程数（MPL）、优化工作集等方式解决。实验中无内存紧张场景，未涉及抖动的检测与处理。

4. 大页管理

   OS 原理中，大页（如 2MB、1GB 大页）可减少页表项数量、提升 TLB 命中率，是优化内存访问效率的重要手段。实验中仅使用 4KB 小页，未实现大页的映射与管理。

5. TLB 优化

   OS 原理中，TLB（快表）是加速地址转换的关键，其刷新策略、缺失处理优化（如 TLB 预加载）直接影响系统性能。实验中未涉及 TLB 的管理与优化，仅依赖 MMU 的基础地址转换。

6. Cache 与 MMU 的协同

   OS 原理中，Cache 的三种方案（VIVT、PIPT、VIPT）、Cache 与 MMU 的配合（如虚地址 / 实地址缓存）、进程调度对 Cache 的影响是内存访问优化的核心。实验中未涉及 Cache 相关的任何逻辑。

7. OOM（Out Of Memory）处理

   OS 原理中，内存不足时需通过杀死低优先级进程、挂起进程等方式释放内存，避免系统宕机。实验中无内存耗尽场景，未实现 OOM 处理机制。

8. 内存碎片整理

   OS 原理中，动态分区分配导致的外碎片需通过紧凑技术（内存碎片整理）解决。实验中内存分配依赖 slab 分配器和预映射，未涉及碎片整理逻辑。

9. 共享内存与内存映射文件

   OS 原理中，共享内存是高效的 IPC 方式，内存映射文件是文件 I/O 与内存管理的结合（如 Linux 的 mmap）。实验中无多进程协作需求，未实现相关机制。